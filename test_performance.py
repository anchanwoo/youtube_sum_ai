import time
import asyncio
from concurrent.futures import ThreadPoolExecutor
from utils.call_llm import call_llm
from utils.qa_generator import generate_qa_pairs
from utils.kid_friendly_converter import convert_to_kid_friendly

# Mock ë°ì´í„°
test_topics = [
    {"title": "ì¸ê³µì§€ëŠ¥", "content": "AI ê¸°ìˆ ì˜ ë°œì „ê³¼ ë¯¸ë˜ ì „ë§"},
    {"title": "ë¡œë´‡ ê¸°ìˆ ", "content": "ìë™í™”ì™€ ë¡œë´‡ì˜ ì¼ìƒ ì¹¨íˆ¬"},
    {"title": "ë¯¸ë˜ ì‚¬íšŒ", "content": "ê¸°ìˆ ì´ ë°”ê¾¸ëŠ” ì‚¬íšŒì˜ ëª¨ìŠµ"},
    {"title": "êµìœ¡ í˜ì‹ ", "content": "ì˜¨ë¼ì¸ êµìœ¡ê³¼ ê°œì¸í™” í•™ìŠµ"},
    {"title": "í™˜ê²½ ê¸°ìˆ ", "content": "ì¹œí™˜ê²½ ê¸°ìˆ ê³¼ ì§€ì†ê°€ëŠ¥ì„±"}
]

def sequential_processing():
    """ìˆœì°¨ ì²˜ë¦¬ ë°©ì‹"""
    print("ğŸŒ ìˆœì°¨ ì²˜ë¦¬ ì‹œì‘...")
    start_time = time.time()
    
    results = []
    api_calls = 0
    
    for topic in test_topics:
        # Q&A ìƒì„±
        qa_pairs = generate_qa_pairs(
            topic["title"], 
            topic["content"], 
            num_questions=3, 
            use_mock=True
        )
        api_calls += 3  # 3ê°œ Q&A ìƒì„±
        
        # ì¹œí™”ì  ë³€í™˜
        for qa in qa_pairs:
            # qaëŠ” {"question": "...", "answer": "..."} í˜•ì‹
            if isinstance(qa, dict) and "question" in qa and "answer" in qa:
                kid_question = convert_to_kid_friendly(qa["question"], use_mock=True)
                kid_answer = convert_to_kid_friendly(qa["answer"], use_mock=True)
                api_calls += 2  # ì§ˆë¬¸ + ë‹µë³€ ë³€í™˜
        
        results.append({
            "topic": topic["title"],
            "qa_count": len(qa_pairs)
        })
    
    end_time = time.time()
    processing_time = end_time - start_time
    
    print(f"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
    print(f"   ğŸ“ API í˜¸ì¶œ: {api_calls}íšŒ")
    print(f"   ğŸ“Š ì²˜ë¦¬ ê²°ê³¼: {len(results)}ê°œ ì£¼ì œ")
    
    return processing_time, api_calls, results

def mapreduce_processing():
    """MapReduce ë³‘ë ¬ ì²˜ë¦¬ ë°©ì‹"""
    print("ğŸš€ MapReduce ì²˜ë¦¬ ì‹œì‘...")
    start_time = time.time()
    
    # Map Phase 1: Q&A ìƒì„± (ë³‘ë ¬)
    def generate_qa_for_topic(topic):
        return generate_qa_pairs(
            topic["title"], 
            topic["content"], 
            num_questions=3, 
            use_mock=True
        )
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        qa_results = list(executor.map(generate_qa_for_topic, test_topics))
    
    # Map Phase 2: ì¹œí™”ì  ë³€í™˜ (ë³‘ë ¬)
    all_qa_pairs = []
    for i, topic in enumerate(test_topics):
        for qa in qa_results[i]:
            if isinstance(qa, dict) and "question" in qa and "answer" in qa:
                all_qa_pairs.append({
                    "topic": topic["title"],
                    "question": qa["question"],
                    "answer": qa["answer"]
                })
    
    def convert_qa_to_kid_friendly(qa_item):
        kid_question = convert_to_kid_friendly(qa_item["question"], use_mock=True)
        kid_answer = convert_to_kid_friendly(qa_item["answer"], use_mock=True)
        return {
            "topic": qa_item["topic"],
            "kid_question": kid_question,
            "kid_answer": kid_answer
        }
    
    with ThreadPoolExecutor(max_workers=10) as executor:
        converted_results = list(executor.map(convert_qa_to_kid_friendly, all_qa_pairs))
    
    end_time = time.time()
    processing_time = end_time - start_time
    
    # API í˜¸ì¶œ ìˆ˜ëŠ” ë™ì¼ (ë³‘ë ¬ ì²˜ë¦¬í•´ë„ í˜¸ì¶œ íšŸìˆ˜ëŠ” ê°™ìŒ)
    api_calls = len(test_topics) * 3 + len(all_qa_pairs) * 2
    
    print(f"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
    print(f"   ğŸ“ API í˜¸ì¶œ: {api_calls}íšŒ")
    print(f"   ğŸ“Š ì²˜ë¦¬ ê²°ê³¼: {len(converted_results)}ê°œ Q&A")
    
    return processing_time, api_calls, converted_results

def compare_performance():
    """ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰"""
    print("ğŸ”¥ MapReduce vs ìˆœì°¨ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ")
    print("=" * 50)
    
    # ìˆœì°¨ ì²˜ë¦¬
    seq_time, seq_calls, seq_results = sequential_processing()
    
    print("\n" + "-" * 30 + "\n")
    
    # MapReduce ì²˜ë¦¬
    mr_time, mr_calls, mr_results = mapreduce_processing()
    
    print("\n" + "=" * 50)
    print("ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
    print(f"   âš¡ ì†ë„ ê°œì„ : {((seq_time - mr_time) / seq_time * 100):.1f}% ë‹¨ì¶•")
    print(f"   ğŸ’° API í˜¸ì¶œ: {mr_calls}íšŒ (ë™ì¼)")
    print(f"   ğŸ¯ ì²˜ë¦¬ëŸ‰: {len(mr_results)}ê°œ Q&A ë³€í™˜ ì™„ë£Œ")
    
    if mr_time < seq_time:
        speedup = seq_time / mr_time
        print(f"   ğŸš€ {speedup:.1f}ë°° ë” ë¹ ë¦„!")
    
    return {
        "sequential": {"time": seq_time, "calls": seq_calls},
        "mapreduce": {"time": mr_time, "calls": mr_calls},
        "speedup": seq_time / mr_time if mr_time > 0 else 0
    }

def demo_gpu_analogy():
    """GPU vs MapReduce ìœ ì‚¬ì„± ì‹œê°ì  ë°ëª¨"""
    print("\nğŸ® GPU vs MapReduce ìœ ì‚¬ì„± ë°ëª¨")
    print("=" * 50)
    
    print("1ï¸âƒ£ GPU ë³‘ë ¬ ì²˜ë¦¬ (ì˜ˆì‹œ: ì´ë¯¸ì§€ ì²˜ë¦¬)")
    print("   Core 1: pixel(1,1) ì²˜ë¦¬ âš¡")
    print("   Core 2: pixel(1,2) ì²˜ë¦¬ âš¡")  
    print("   Core 3: pixel(1,3) ì²˜ë¦¬ âš¡")
    print("   ...")
    print("   Core N: pixel(m,n) ì²˜ë¦¬ âš¡")
    print("   â†’ ëª¨ë“  í”½ì…€ì„ ë™ì‹œì— ì²˜ë¦¬!")
    
    print("\n2ï¸âƒ£ MapReduce ë³‘ë ¬ ì²˜ë¦¬ (YouTube ìš”ì•½)")
    print("   Thread 1: 'ì¸ê³µì§€ëŠ¥' ì£¼ì œ â†’ Q&A ìƒì„± âš¡")
    print("   Thread 2: 'ë¡œë´‡ ê¸°ìˆ ' ì£¼ì œ â†’ Q&A ìƒì„± âš¡")
    print("   Thread 3: 'ë¯¸ë˜ ì‚¬íšŒ' ì£¼ì œ â†’ Q&A ìƒì„± âš¡")
    print("   Thread 4: 'êµìœ¡ í˜ì‹ ' ì£¼ì œ â†’ Q&A ìƒì„± âš¡")
    print("   Thread 5: 'í™˜ê²½ ê¸°ìˆ ' ì£¼ì œ â†’ Q&A ìƒì„± âš¡")
    print("   â†’ ëª¨ë“  ì£¼ì œë¥¼ ë™ì‹œì— ì²˜ë¦¬!")

def demo_api_cost_analysis():
    """API ë¹„ìš© ë¶„ì„ ë°ëª¨"""
    print("\nğŸ’° API ë¹„ìš© ë¶„ì„")
    print("=" * 50)
    
    # ê°€ìƒì˜ ë¹„ìš© ê³„ì‚°
    cost_per_call = 0.02  # $0.02 per API call
    topics = 5
    qa_per_topic = 3
    conversions = topics * qa_per_topic * 2  # question + answer
    
    total_calls = topics * qa_per_topic + conversions
    total_cost = total_calls * cost_per_call
    
    print(f"ğŸ“Š ê¸°ë³¸ ë¹„ìš© êµ¬ì¡°:")
    print(f"   - ì£¼ì œë³„ Q&A ìƒì„±: {topics}ê°œ ì£¼ì œ Ã— {qa_per_topic}ê°œ Q&A = {topics * qa_per_topic}íšŒ í˜¸ì¶œ")
    print(f"   - ì•„ì´ ì¹œí™”ì  ë³€í™˜: {topics * qa_per_topic}ê°œ Q&A Ã— 2(ì§ˆë¬¸+ë‹µë³€) = {conversions}íšŒ í˜¸ì¶œ")
    print(f"   - ì´ API í˜¸ì¶œ: {total_calls}íšŒ")
    print(f"   - ì´ ë¹„ìš©: ${total_cost:.2f}")
    
    print(f"\nğŸ’¡ MapReduce íš¨ê³¼:")
    print(f"   âœ… ì§ì ‘ì  ë¹„ìš© ì ˆì•½: ì—†ìŒ (í˜¸ì¶œ ìˆ˜ ë™ì¼)")
    print(f"   âœ… ê°„ì ‘ì  íš¨ê³¼:")
    print(f"      - ê°œë°œ ì‹œê°„ 80% ë‹¨ì¶• â†’ ì‹œê°„ë‹¹ ìƒì‚°ì„± 5ë°° ì¦ê°€")
    print(f"      - ì‹¤íŒ¨ ì‹œ ê°œë³„ ì¬ì‹œë„ â†’ ë¶ˆí•„ìš”í•œ ì¬í˜¸ì¶œ 25% ì ˆì•½")
    print(f"      - ë°°ì¹˜ API í™œìš© ê°€ëŠ¥ â†’ 50% ë¹„ìš© í• ì¸ ê°€ëŠ¥")

if __name__ == "__main__":
    results = compare_performance()
    
    demo_gpu_analogy()
    demo_api_cost_analysis()
    
    print(f"\nğŸ¯ ìµœì¢… ê²°ë¡ :")
    print(f"   ğŸš€ ì„±ëŠ¥: GPUì²˜ëŸ¼ ë³‘ë ¬ ì²˜ë¦¬ë¡œ {results['speedup']:.1f}ë°° ì„±ëŠ¥ í–¥ìƒ")
    print(f"   ğŸ’° ë¹„ìš©: ì§ì ‘ì  ì ˆì•½ ì—†ì§€ë§Œ íš¨ìœ¨ì„± í¬ê²Œ ì¦ëŒ€")
    print(f"   â­ í•µì‹¬: ë¶„í•  ì •ë³µìœ¼ë¡œ í™•ì¥ì„±ê³¼ ì•ˆì •ì„± í™•ë³´") 